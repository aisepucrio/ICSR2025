{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tuxml\n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#definitions\n",
    "# systems = ['7z','BerkeleyDBC','Dune','Hipacc','Irzip','LLVM','Polly','x264']\n",
    "# systems = ['LLVM','x264','BerkeleyDBC','Irzip','Polly','7z','Hipacc','Dune']\n",
    "systems = ['Hipacc']\n",
    "\n",
    "# samples_config = ['random']\n",
    "samples_config = ['distBased', 'divDistBased','henard', 'random', 'solverBased', 'twise']\n",
    "# samples_config = ['distBased']\n",
    "size_methods = [\"Performance\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning a model by using linear regression\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "def run_regressorML(reg, test_size, size_target, x_train, x_test, y_train, y_test):\n",
    "    assert(size_target in size_methods)\n",
    "    reg.fit(x_train, y_train)       \n",
    "    y_pred = reg.predict(x_test)\n",
    "    #y_pred = reg.intercept_ + np.sum(reg.coef_ * x_test.values, axis=1)\n",
    "    dfErrors = pd.DataFrame({'Actual':y_test, 'Predicted':y_pred, \"error\":(y_pred - y_test).abs(), \"% error\":((y_pred - y_test)/y_test).abs()*100})\n",
    "    return dfErrors[\"% error\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "\n",
    "def ft_importances(coef_, col):\n",
    "    importanceSeries = pd.Series(coef_, index=col.values)\n",
    "    return importanceSeries[importanceSeries != 0].abs().sort_values(ascending = False)\n",
    "\n",
    "def ft_importances_RF(X, y):\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    feature_importances = model.feature_importances_\n",
    "    features = pd.DataFrame({'feature': X.columns, 'importance': feature_importances})\n",
    "    features.sort_values('importance', ascending=False, inplace=True)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def ft_importances_DT(X, y):\n",
    "    model = tree.DecisionTreeRegressor(random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    feature_importances = model.feature_importances_\n",
    "    features = pd.DataFrame({'feature': X.columns, 'importance': feature_importances})\n",
    "    features.sort_values('importance', ascending=False, inplace=True)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def ft_importances_GB(X, y):\n",
    "    model = GradientBoostingRegressor(random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    feature_importances = model.feature_importances_\n",
    "    features = pd.DataFrame({'feature': X.columns, 'importance': feature_importances})\n",
    "    features.sort_values('importance', ascending=False, inplace=True)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm_name</th>\n",
       "      <th>ft_dummyfication</th>\n",
       "      <th>origin_ft_selection</th>\n",
       "      <th>ft_selection</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>size_target</th>\n",
       "      <th>test_size</th>\n",
       "      <th>coef_order</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [algorithm_name, ft_dummyfication, origin_ft_selection, ft_selection, hyperparameters, size_target, test_size, coef_order, accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result  = pd.DataFrame(columns = ['algorithm_name', 'ft_dummyfication', 'origin_ft_selection', 'ft_selection', 'hyperparameters', 'size_target', 'test_size', 'coef_order', 'accuracy'])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "%run feature_importance-all_systems.ipynb\n",
    "\n",
    "\n",
    "def run_Algorithms(df, ft_importance_enable, system=None):\n",
    "    \n",
    "    samples_config = ['distBased', 'divDistBased','henard', 'random', 'solverBased', 'twise']\n",
    "    size_methods = [\"Performance\"]\n",
    "    \n",
    "    for config_name in samples_config:\n",
    "        \n",
    "        df_result = pd.DataFrame(columns = ['algorithm_name', 'ft_dummyfication', 'origin_ft_selection', 'ft_selection', 'hyperparameters', 'size_target', 'test_size', 'coef_order', 'accuracy', 'num_features'])\n",
    "        \n",
    "        print(config_name)\n",
    "        path_name = config_name+\"_t3\"\n",
    "        if(system==None):\n",
    "            path = r\"sampledConfigurations_\"+path_name+\".csv\"\n",
    "        else:\n",
    "            path = system+\"/sampledConfigurations_\"+path_name+\".csv\"\n",
    "            \n",
    "        if not ft_importance_enable:\n",
    "            samplePerc_lst = [1.0]\n",
    "        else:\n",
    "            samplePerc_lst = [0.3,0.4,0.5,0.6]\n",
    "            \n",
    "        for samplePerc in samplePerc_lst:\n",
    "            print(samplePerc)\n",
    "            df = pd.read_csv(path, sep=';')\n",
    "            \n",
    "            if ft_importance_enable:\n",
    "                #Run fetures engines: #yes and encoding\n",
    "                df = run_feature_encoding(run_features_engine_yes(df))\n",
    "\n",
    "                path_name = config_name+\"_t3_features_engine\"\n",
    "            else:\n",
    "                df = run_features_engine_yes(df)\n",
    "\n",
    "            \n",
    "            #display(df)\n",
    "            #number of features after features engine execution\n",
    "            num_features = round(samplePerc*len(df.columns))\n",
    "\n",
    "            start_time_sample = pd.Timestamp.now()\n",
    "            \n",
    "            \n",
    "            #Run feature selection\n",
    "            if ft_importance_enable:\n",
    "                run_featureSelection(df, system, None, path_name,'RandomForest')\n",
    "                df_importance = pd.read_csv(system+f\"/feature_importance_{path_name}_RF.csv\")\n",
    "\n",
    "                print(\"Sample features number: \"+ str(num_features))\n",
    "                df_importance = df[df_importance[:num_features][\"Unnamed: 0\"].values]\n",
    "                df_importance.head()\n",
    "\n",
    "\n",
    "            target = \"Performance\"\n",
    "            paramsLasso = {'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01],\n",
    "                           'max_iter': [1, 5, 10, 100, 1000],}\n",
    "            paramsRidge = {'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01]}\n",
    "            paramsENet = {'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01],\n",
    "                          'l1_ratio': [0.0, 0.5, 1.0, 0.1],\n",
    "                          'max_iter': [1, 5, 10, 100, 1000],}\n",
    "            paramsRF =  {\"max_depth\":18,\"n_estimators\":50,\"verbose\":2}\n",
    "\n",
    "            #Modifiquei os dicionários para quando a feature importance está ativada. Acho que não fazia muito sentido \n",
    "            #manter o uso do random forest quando feature importance for False, da mesma forma que não é viável manter\n",
    "            #o None quando está ativado\n",
    "            \n",
    "            if ft_importance_enable:\n",
    "                ft_selection =  {'DecisionTree': df_importance.columns[:num_features]}\n",
    "            else:\n",
    "                ft_selection =  {'None': df.drop(columns=size_methods).columns}\n",
    "\n",
    "            for origin_ft_selection in ft_selection:\n",
    "                print(origin_ft_selection)\n",
    "                if ft_importance_enable:\n",
    "                    print('IN FT_LOOP DF IMPORTANCE\\n')\n",
    "                    display(df_importance)\n",
    "\n",
    "                for size in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "                    config_start_time = pd.Timestamp.now()\n",
    "\n",
    "                    # size = number of configurations\n",
    "                    x_train, x_test, y_train, y_test = train_test_split(df[ft_selection[origin_ft_selection]], df[target], train_size=size, random_state=42)\n",
    "                    x_train, y_train = np.array(x_train.values), np.array(y_train.values)\n",
    "\n",
    "\n",
    "                    if len(x_train) > 3:\n",
    "\n",
    "                        model = {'LinearRegression': LinearRegression(),\n",
    "                                 'Lasso': GridSearchCV(linear_model.Lasso(), param_grid=paramsLasso, cv=3).fit(x_train, y_train).best_estimator_,\n",
    "                                 'Ridge': GridSearchCV(linear_model.Ridge(), param_grid=paramsRidge, cv=3).fit(x_train, y_train).best_estimator_,\n",
    "                                 'ElasticNet': GridSearchCV(ElasticNet(), param_grid=paramsENet, scoring='r2', cv=3).fit(x_train, y_train).best_estimator_,\n",
    "                                 'PolynomialRegression': LinearRegression(),\n",
    "                                 'RandomForest': ensemble.RandomForestRegressor(),\n",
    "                                 'GradientBoostingTree': ensemble.GradientBoostingRegressor(),\n",
    "                                 'DecisionTree': tree.DecisionTreeRegressor()}\n",
    "                    else:\n",
    "                        if len(x_train) >= 2:\n",
    "                            model = {'LinearRegression': LinearRegression(),\n",
    "                                     'Lasso': GridSearchCV(linear_model.Lasso(), param_grid=paramsLasso, cv=2).fit(x_train, y_train).best_estimator_,\n",
    "                                     'Ridge': GridSearchCV(linear_model.Ridge(), param_grid=paramsRidge, cv=2).fit(x_train, y_train).best_estimator_,\n",
    "                                     'ElasticNet': GridSearchCV(ElasticNet(), param_grid=paramsENet, scoring='r2', cv=2).fit(x_train, y_train).best_estimator_,\n",
    "                                     'PolynomialRegression': LinearRegression(),\n",
    "                                     'RandomForest': ensemble.RandomForestRegressor(),\n",
    "                                     'GradientBoostingTree': ensemble.GradientBoostingRegressor(),\n",
    "                                     'DecisionTree': tree.DecisionTreeRegressor()}\n",
    "\n",
    "                    for key in model:\n",
    "                        print(key)\n",
    "                        if (key == 'PolynomialRegression') and (origin_ft_selection == 'None'):\n",
    "                            print(\"It doesn't scale\")\n",
    "                        else:\n",
    "                            if (key == 'PolynomialRegression'):\n",
    "                                #for 2 options we have: 𝑓(𝑥₁, 𝑥₂) = 𝑏₀ + 𝑏₁𝑥₁ + 𝑏₂𝑥₂ + 𝑏₃𝑥₁² + 𝑏₄𝑥₁𝑥₂ + 𝑏₅𝑥₂²\n",
    "                                x_train = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x_train)\n",
    "                                x_test = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x_test)\n",
    "\n",
    "                            res_model = run_regressorML(model[key], test_size=size, size_target=target, x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test)\n",
    "\n",
    "                            if (key == 'PolynomialRegression'):\n",
    "                                model[key].coef_ = model[key].coef_[:num_features]\n",
    "                                \n",
    "                            if (key == 'DecisionTree' or key == 'RandomForest' or key == 'GradientBoostingTree'):\n",
    "                                coef_order = ft_importances(res_model[:num_features], col=ft_selection[origin_ft_selection])\n",
    "                            else:\n",
    "                                coef_order = ft_importances(model[key].coef_, col=ft_selection[origin_ft_selection])\n",
    "\n",
    "#                             df_result.loc[len(df_result)] = [key, ft_dummyfication, origin_ft_selection, ft_selection[origin_ft_selection], model[key], target, size, coef_order, res_model]\n",
    "                            df_result.loc[len(df_result)] = [key, False, origin_ft_selection, ft_selection[origin_ft_selection], model[key], target, size, coef_order, res_model, str(num_features)]\n",
    "                            display(df_result)\n",
    "                            \n",
    "                        config_end_time = pd.Timestamp.now()\n",
    "                        exec_time = [config_name,samplePerc,num_features,ft_importance_enable,origin_ft_selection, key, size,False,config_start_time,config_end_time]\n",
    "    #             exec_time = [config_name,samplePerc,num_features,ft_importance_enable,origin_ft_selection, key, size,ft_dummyfication,config_start_time,config_end_time]\n",
    "                        df_time.loc[df_time.size] = exec_time\n",
    "\n",
    "            sample_end_time = pd.Timestamp.now()\n",
    "            exec_time = [config_name,samplePerc,num_features,ft_importance_enable,origin_ft_selection, key, None,None,start_time_sample,sample_end_time]\n",
    "            df_time.loc[df_time.size] = exec_time\n",
    "#             display(df_result)\n",
    "\n",
    "            if ft_importance_enable:\n",
    "                df_result.to_csv(\"results/\"+system+\"/\"+system+\"-results_with_feature_importance_\"+path_name+\"_\"+str(num_features)+\"_v3_RF.csv\", header=True)\n",
    "            else:\n",
    "                df_result.to_csv(\"results/\"+system+\"/\"+system+\"-results_\"+path_name+\"_full_v3_RF.csv\", header=True)\n",
    "\n",
    "        display(df_result)\n",
    "                                                                                                                                  \n",
    "    if ft_importance_enable:\n",
    "        time_file_name = \"results/\"+system+\"/\"+system+\"-simulation_time_information-with_feature_importance_v3_RF.csv\"\n",
    "    else:\n",
    "        time_file_name = \"results/\"+system+\"/\"+system+\"-simulation_time_information_v3_RF.csv\"\n",
    "    \n",
    "    df_time.to_csv(time_file_name)\n",
    "        \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hipacc\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "--------------- System Hipacc training WITHOUT features importance \n",
      "\n",
      "--------------- Start time:: 2024-03-30 16:11:09.832922\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "distBased\n",
      "1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_time = pd.DataFrame(columns=['SampleAlgorithm','%FeatureSelection','#Features','FeatureImportance','OriginalFS','Algorithm','%Configurations','Dummy','StartTime', 'EndTime'])\n",
    "\n",
    "for system in systems:\n",
    "    print(system)\n",
    "    \n",
    "    print(\"\\n\\n-----------------------------------------------------------------------------\")\n",
    "    print(\"\\n--------------- System \"+ system+ \" training WITHOUT features importance \")\n",
    "    print(\"\\n--------------- Start time:: \" + str(pd.Timestamp.now()))\n",
    "    print(\"\\n-----------------------------------------------------------------------------\")\n",
    "    df_result_nfi = run_Algorithms(None, False, system)\n",
    "    print(\"\\n\\n-----------------------------------------------------------------------------\")\n",
    "    print(\"\\n--------------- System \"+ system+ \" training \")\n",
    "    print(\"\\n--------------- End time:: \" + str(pd.Timestamp.now()))\n",
    "    print(\"\\n-----------------------------------------------------------------------------\")\n",
    "    \n",
    "    print(\"\\n\\n-----------------------------------------------------------------------------\")\n",
    "    print(\"\\n--------------- System \"+ system+ \" training WITH features importance \")\n",
    "    print(\"\\n--------------- Start time:: \" + str(pd.Timestamp.now()))\n",
    "    print(\"\\n-----------------------------------------------------------------------------\")\n",
    "    df_result_fi = run_Algorithms(None, True, system)\n",
    "    print(\"\\n\\n-----------------------------------------------------------------------------\")\n",
    "    print(\"\\n--------------- System \"+ system+ \" training \")\n",
    "    print(\"\\n--------------- End time:: \" + str(pd.Timestamp.now()))\n",
    "    print(\"\\n-----------------------------------------------------------------------------\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['accuracy'][0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "rs = []\n",
    "for i in range(len(df_result_fi['accuracy'])):\n",
    "    rs.append(df_result_fi['accuracy'][i]['mean'])\n",
    "\n",
    "# rs\n",
    "# display (df_result['algorithm_name'], df_result['accuracy'], rs)\n",
    "\n",
    "plt.scatter(df_result_fi['algorithm_name'], rs, color =\"blue\", marker = \"s\")\n",
    "plt.plot(df_result_fi['algorithm_name'], rs, color =\"blue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = [model['LinearRegression'].coef_, model['Lasso'].coef_, model['Ridge'].coef_, model['ElasticNet'].coef_, model['PolynomialRegression'].coef_]\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Coeficient of feature importance for all algorithms')\n",
    "ax1.boxplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
