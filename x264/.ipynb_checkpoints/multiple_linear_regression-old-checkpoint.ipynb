{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tuxml\n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#df = tuxml.load_dataset()\n",
    "# path = r\"x264/sampledConfigurations_distBased_t3.csv\"\n",
    "#path = r\"sampledConfigurations_distBased_t3.csv\"\n",
    "samples_config = ['distBased', 'divDistBased','henard', 'random', 'solverBased', 'twise']\n",
    "\n",
    "# for config_name in samples_config:\n",
    "#     path = r\"sampledConfigurations_\"+config_name+\"_t3.csv\"\n",
    "# #     df.append(pd.read_csv(path, sep=';'))\n",
    "#     display(path)\n",
    "\n",
    "# df = pd.read_csv(path, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_importance = pd.read_csv(\"feature_importanceRF.csv\")\n",
    "# df_importance = df[df_importance[:100][\"Unnamed: 0\"].values]\n",
    "# df_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size_methods = [\"vmlinux\", \"GZIP-bzImage\", \"GZIP-vmlinux\", \"GZIP\", \"BZIP2-bzImage\", \n",
    "#              \"BZIP2-vmlinux\", \"BZIP2\", \"LZMA-bzImage\", \"LZMA-vmlinux\", \"LZMA\", \"XZ-bzImage\", \"XZ-vmlinux\", \"XZ\", \n",
    "#?              \"LZO-bzImage\", \"LZO-vmlinux\", \"LZO\", \"LZ4-bzImage\", \"LZ4-vmlinux\", \"LZ4\"]\n",
    "\n",
    "size_methods = [\"Performance\"]\n",
    "#additional_ft = [\"nbyes\", \"nbno\", \"nbmodule\", \"nbyesmodule\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning a model by using linear regression\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "def run_regressorML(reg, test_size, size_target, x_train, x_test):\n",
    "    assert(size_target in size_methods)\n",
    "    reg.fit(x_train, y_train)\n",
    "    y_pred = reg.predict(x_test)\n",
    "    #y_pred = reg.intercept_ + np.sum(reg.coef_ * x_test.values, axis=1)\n",
    "    dfErrors = pd.DataFrame({'Actual':y_test, 'Predicted':y_pred, \"error\":(y_pred - y_test).abs(), \"% error\":((y_pred - y_test)/y_test).abs()*100})\n",
    "    return dfErrors[\"% error\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_importances(coef_, col):\n",
    "    importanceSeries = pd.Series(coef_, index=col.values)\n",
    "    return importanceSeries[importanceSeries != 0].abs().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result  = pd.DataFrame(columns = ['algorithm_name', 'ft_dummyfication', 'origin_ft_selection', 'ft_selection', 'hyperparameters', 'size_target', 'test_size', 'coef_order', 'accuracy'])\n",
    "#df_result  = pd.DataFrame(columns = ['algorithm_name', 'hyperparameters', 'size_target', 'additional_ft', 'test_size', 'coef_order', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm_name</th>\n",
       "      <th>ft_dummyfication</th>\n",
       "      <th>origin_ft_selection</th>\n",
       "      <th>ft_selection</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>size_target</th>\n",
       "      <th>test_size</th>\n",
       "      <th>coef_order</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [algorithm_name, ft_dummyfication, origin_ft_selection, ft_selection, hyperparameters, size_target, test_size, coef_order, accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00 -1.77635684e-15  1.47237262e+01  1.40739963e+01\n",
      "  1.10279326e+01  1.57879215e+00  1.47667294e+00 -2.43451650e-01\n",
      " -2.01388684e+00  2.05614246e+00 -3.41053506e+00  1.54899897e+01]\n",
      "[ 0.          0.         14.6558468  13.93056336 10.92357897  1.37023557\n",
      "  1.35098355 -0.         -1.551384    1.61849613 -3.04375662 15.39777002]\n",
      "[ 0.          0.         14.40397144 13.74445042 10.87988478  1.62540347\n",
      "  1.59768858 -0.14993902 -1.85425029  2.13748075 -3.27020239 15.15447028]\n",
      "[ 0.          0.         14.25748978 13.58137147 10.78376724  1.64957623\n",
      "  1.63062322 -0.12543094 -1.79258806  2.18643758 -3.19853379 14.98015168]\n",
      "It doesn't scale\n",
      "[ 0.00000000e+00 -5.32907052e-15  1.52052056e+01  1.41031355e+01\n",
      "  1.06158737e+01  1.58392587e+00  1.07089175e+00  5.68042598e-01\n",
      " -9.36378822e-01  1.77956967e+00 -2.98028500e+00  1.60870907e+01]\n",
      "[ 0.          0.         15.14411304 13.9722141  10.52210635  1.35611904\n",
      "  0.94927087  0.48561551 -0.51208245  1.4825348  -2.62461574 16.02940559]\n",
      "[ 0.          0.         15.08865639 13.98509331 10.57560032  1.5971636\n",
      "  1.12900413  0.5997097  -0.89748615  1.80937269 -2.94408457 15.97023606]\n",
      "[ 0.          0.         15.14411304 13.9722141  10.52210635  1.35611904\n",
      "  0.94927087  0.48561551 -0.51208245  1.4825348  -2.62461574 16.02940559]\n",
      "It doesn't scale\n",
      "[ 0.00000000e+00  8.88178420e-16  1.59750363e+01  1.46782543e+01\n",
      "  1.08100770e+01  1.17352117e+00  1.23104976e+00 -1.22258818e+00\n",
      " -1.65301121e+00  1.59146139e+00 -2.53928015e+00  1.59666023e+01]\n",
      "[ 0.          0.         15.97013834 14.62981671 10.72019813  1.08585339\n",
      "  1.1567445  -1.14147633 -1.54987596  1.52824156 -2.4738387  15.98411816]\n",
      "[ 0.          0.         15.73988815 14.430148   10.71447035  1.23492515\n",
      "  1.31458947 -1.10370157 -1.56590896  1.63583257 -2.47524837 15.76333965]\n",
      "[ 0.          0.         15.69281669 14.3545189  10.6252889   1.18650834\n",
      "  1.27284994 -1.04659938 -1.50006195  1.62520201 -2.43090012 15.74323346]\n",
      "It doesn't scale\n",
      "[ 0.00000000e+00 -5.32907052e-15  1.52368884e+01  1.54293468e+01\n",
      "  1.17308258e+01  1.88346327e+00  1.77690486e+00 -5.36215494e-01\n",
      " -1.62729985e+00  1.31630671e+00 -2.21386502e+00  1.53078765e+01]\n",
      "[ 0.          0.         15.15834979 15.03959009 11.47326588  1.49929966\n",
      "  1.53637802 -0.         -0.7477368   0.62319585 -1.56974674 15.09159597]\n",
      "[ 0.          0.         15.23187645 15.423461   11.72826549  1.88469724\n",
      "  1.77827913 -0.53325454 -1.62527865  1.31766554 -2.21301836 15.3033807 ]\n",
      "[ 0.          0.         15.15834979 15.03959009 11.47326588  1.49929966\n",
      "  1.53637802 -0.         -0.7477368   0.62319585 -1.56974674 15.09159597]\n",
      "It doesn't scale\n",
      "[ 0.00000000e+00 -8.88178420e-15  1.44198309e+01  1.76296079e+01\n",
      "  1.14797624e+01  8.26444804e-01  1.24649664e+00 -9.23991324e-01\n",
      " -1.77844770e+00  2.39801715e-01 -2.10596281e+00  1.63709999e+01]\n",
      "[ 0.          0.         14.02579631 16.45529527 10.77292384  0.\n",
      "  0.35917806 -0.         -0.          0.         -0.42929874 15.74119336]\n",
      "[ 0.          0.         14.13876611 17.21708019 11.37755686  0.93498766\n",
      "  1.38234441 -0.7500474  -1.70329571  0.3906788  -2.06542153 16.0391086 ]\n",
      "[ 0.          0.         14.02579631 16.45529527 10.77292384  0.\n",
      "  0.35917806 -0.         -0.          0.         -0.42929874 15.74119336]\n",
      "It doesn't scale\n",
      "[ 0.00000000e+00 -1.77635684e-15  1.58916136e+01  1.71388186e+01\n",
      "  1.12611348e+01  1.85067655e-01  2.34858519e+00 -1.60930703e-01\n",
      " -1.53410867e+00 -1.31078369e-01 -1.64581429e+00  1.47723225e+01]\n",
      "[ 0.          0.         15.60335076 16.47831966 10.72698998  0.\n",
      "  1.72719706  0.         -0.47637983  0.         -0.61546448 14.39108812]\n",
      "[ 0.00000000e+00  0.00000000e+00  1.56615762e+01  1.68610882e+01\n",
      "  1.11632305e+01  2.46358496e-01  2.45575991e+00 -1.66046626e-02\n",
      " -1.47053539e+00 -6.22885963e-02 -1.68831449e+00  1.45782375e+01]\n",
      "[ 0.          0.         15.60335076 16.47831966 10.72698998  0.\n",
      "  1.72719706  0.         -0.47637983  0.         -0.61546448 14.39108812]\n",
      "It doesn't scale\n",
      "[ 0.00000000e+00  2.66453526e-15  1.62310562e+01  1.84301719e+01\n",
      "  1.05290697e+01 -1.03419115e+00  1.81021569e+00 -1.09518452e+00\n",
      " -9.67725145e-01 -5.65983106e-01 -7.81688811e-01  1.46187478e+01]\n",
      "[ 0.          0.         15.24470959 16.32474388  8.81502476 -0.\n",
      "  0.04055069 -0.         -0.          0.         -0.         14.11917339]\n",
      "[ 0.00000000e+00  0.00000000e+00  1.41913810e+01  1.58061792e+01\n",
      "  9.55909248e+00  1.78682202e-01  2.54363914e+00 -2.32048911e-01\n",
      " -9.20998702e-01 -1.07412416e-02 -1.77027263e+00  1.35120931e+01]\n",
      "[ 0.          0.         15.24470959 16.32474388  8.81502476 -0.\n",
      "  0.04055069 -0.         -0.          0.         -0.         14.11917339]\n",
      "It doesn't scale\n",
      "[ 0.00000000e+00 -7.10542736e-15  1.39744632e+01  1.38612832e+01\n",
      "  1.16767721e+01  2.63528700e+00  1.10359697e+00 -4.27478466e+00\n",
      " -2.71603265e+00  5.85322735e+00 -3.72755983e+00  1.85755589e+01]\n",
      "[ 0.          0.         15.30601046 14.93758244  9.68625832  0.\n",
      "  0.80520875 -0.         -0.          0.43597898 -0.12679518 16.35078748]\n",
      "[ 0.          0.         12.98477337 12.4576625  10.76330851  3.5023177\n",
      "  1.76967387 -2.79427173 -2.03205617  4.88007364 -3.99933438 16.89061078]\n",
      "[ 0.          0.         15.30601046 14.93758244  9.68625832  0.\n",
      "  0.80520875 -0.         -0.          0.43597898 -0.12679518 16.35078748]\n",
      "It doesn't scale\n",
      "[ 0.00000000e+00  2.30926389e-14  1.26334740e+01  4.86340051e+00\n",
      "  1.82034309e+01  1.95832826e+00  1.63177186e+00 -1.59044728e+01\n",
      " -2.06304436e+00  1.08651534e+01  4.34833714e+00  1.66587250e+01]\n",
      "[  0.           0.          12.15420985   5.01953163  17.40656975\n",
      "   2.065153     2.3010014  -13.95802706  -1.50460295   9.14670259\n",
      "   2.54225527  16.36114008]\n",
      "[  0.           0.          10.76372658   4.79149378  14.69287355\n",
      "   2.98956695   3.101834   -11.45354247  -3.69692988   8.43524439\n",
      "   3.96238091  14.90332113]\n",
      "[  0.           0.          10.55971497   4.76034616  14.36325919\n",
      "   3.09189842   3.23481611 -11.04281355  -3.82372303   8.21070223\n",
      "   3.89920686  14.71894095]\n",
      "It doesn't scale\n",
      "[ 0.          0.         20.43951711 19.05574945]\n",
      "[ 0.          0.         20.06805024 18.66591242]\n",
      "[ 0.          0.         19.96130232 18.59979745]\n",
      "[ 0.          0.         19.69856595 18.34957435]\n",
      "[ 0.00000000e+00 -7.14556183e+11  3.90385167e+14 -3.09923429e+13]\n",
      "[ 0.00000000e+00 -3.55271368e-15  2.11280339e+01  2.01037199e+01]\n",
      "[ 0.          0.         20.93852628 19.90512716]\n",
      "[ 0.          0.         20.67634335 19.66130904]\n",
      "[ 0.          0.         20.42157411 19.41183433]\n",
      "[ 0.00000000e+00 -9.41548826e+13  7.02390568e+14 -3.11669879e+15]\n",
      "[ 0.          0.         22.92488716 20.40810263]\n",
      "[ 0.          0.         24.17530468 19.36558805]\n",
      "[ 0.          0.         22.84986445 20.34054269]\n",
      "[ 0.         0.        24.0000423 19.4112212]\n",
      "[ 0.00000000e+00  3.24466728e+13  1.87334413e+15 -2.11964790e+15]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "# def runFeatureSelection(df, config_name, num_features): \n",
    "for config_name in samples_config:\n",
    "    for samplePerc in [0.3,0.4,0.5,0.6]:\n",
    "        path = r\"sampledConfigurations_\"+config_name+\"_t3.csv\"\n",
    "        df = pd.read_csv(path, sep=';')\n",
    "        num_features = round(samplePerc*len(df.columns))\n",
    " \n",
    "        target = \"Performance\"\n",
    "        paramsLasso = {'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01],\n",
    "                       'max_iter': [1, 5, 10, 100, 1000],}\n",
    "        paramsRidge = {'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01]}\n",
    "        paramsENet = {'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01],\n",
    "                      'l1_ratio': [0.0, 0.5, 1.0, 0.1],\n",
    "                      'max_iter': [1, 5, 10, 100, 1000],}\n",
    "\n",
    "        for ft_dummyfication in [False, True]:\n",
    "            if ft_dummyfication:\n",
    "                #Creating dummy variables in pandas\n",
    "                df = pd.get_dummies(df, columns=list(df.drop(columns=size_methods).columns.values))\n",
    "                #df_importance = pd.get_dummies(df_importance, columns=list(df_importance.drop(columns=[\"nbyes\", \"nbno\", \"nbyesmodule\"]).columns.values))\n",
    "\n",
    "            #print('Performance' in df.columns)\n",
    "            ft_selection =  {'None': df.drop(columns=size_methods).columns,\n",
    "                             'RandomForest': df.columns[:num_features],}\n",
    "        #    ft_selection =  {'None': df.drop(columns=[\"cid\"]).drop(columns=size_methods).columns,\n",
    "        #                     'RandomForest': df_importance.columns[:100],}\n",
    "\n",
    "            for origin_ft_selection in ft_selection:\n",
    "                for size in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "\n",
    "                    x_train, x_test, y_train, y_test = train_test_split(df[ft_selection[origin_ft_selection]], df[target], test_size=size, random_state=42)  \n",
    "                    x_train, y_train = np.array(x_train.values), np.array(y_train.values)\n",
    "\n",
    "                    model = {'LinearRegression': LinearRegression(),\n",
    "                             'Lasso': GridSearchCV(linear_model.Lasso(), param_grid=paramsLasso, cv=3).fit(x_train, y_train).best_estimator_,\n",
    "                             'Ridge': GridSearchCV(linear_model.Ridge(), param_grid=paramsRidge, cv=3).fit(x_train, y_train).best_estimator_,\n",
    "                             'ElasticNet': GridSearchCV(ElasticNet(), param_grid=paramsENet, scoring='r2', cv=3).fit(x_train, y_train).best_estimator_,\n",
    "                             'PolynomialRegression': LinearRegression()}\n",
    "\n",
    "                    for key in model:\n",
    "                        if (key == 'PolynomialRegression') and (origin_ft_selection == 'None'):\n",
    "                            print(\"It doesn't scale\")\n",
    "                        else:\n",
    "                            if (key == 'PolynomialRegression'):\n",
    "                                #for 2 options we have: 𝑓(𝑥₁, 𝑥₂) = 𝑏₀ + 𝑏₁𝑥₁ + 𝑏₂𝑥₂ + 𝑏₃𝑥₁² + 𝑏₄𝑥₁𝑥₂ + 𝑏₅𝑥₂²\n",
    "                                x_train = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x_train)\n",
    "                                x_test = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x_test)\n",
    "\n",
    "                            res_model = run_regressorML(model[key], test_size=size, size_target=target, x_train=x_train, x_test=x_test)\n",
    "\n",
    "                            if (key == 'PolynomialRegression'):\n",
    "                                model[key].coef_ = model[key].coef_[:num_features]\n",
    "\n",
    "                            print(model[key].coef_)\n",
    "                            coef_order = ft_importances(model[key].coef_, col=ft_selection[origin_ft_selection])\n",
    "                            df_result.loc[len(df_result)] = [key, ft_dummyfication, origin_ft_selection, ft_selection[origin_ft_selection], model[key], target, size, coef_order, res_model]\n",
    "        \n",
    "        \n",
    "        config_id_d = \"Configuration \" + config_name+\" sample with \"+str(num_features)+ \" features selected\"\n",
    "        display(config_id_d)\n",
    "        display(df_result)\n",
    "        df_result.to_csv(\"results_\"+config_name+\"_\"+str(num_features)+\".csv\", header=True)\n",
    "        df_result['accuracy'][0]\n",
    "        rs = []\n",
    "        for i in range(len(df_result['accuracy'])):\n",
    "            rs.append(df_result['accuracy'][i]['mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result['accuracy'][0]\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "# rs = []\n",
    "# for i in range(len(df_result['accuracy'])):\n",
    "#     rs.append(df_result['accuracy'][i]['mean'])\n",
    "\n",
    "# # rs\n",
    "# # display (df_result['algorithm_name'], df_result['accuracy'], rs)\n",
    "\n",
    "# plt.scatter(df_result['algorithm_name'], rs, color =\"blue\", marker = \"s\")\n",
    "# plt.plot(df_result['algorithm_name'], rs, color =\"blue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# data = [model['LinearRegression'].coef_, model['Lasso'].coef_, model['Ridge'].coef_, model['ElasticNet'].coef_, model['PolynomialRegression'].coef_]\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.set_title('Coeficient of feature importance for all algorithms')\n",
    "# ax1.boxplot(data)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
